= Spark History Server

*Spark History Server* is the web UI of xref:ROOT:spark-SparkListener-EventLoggingListener.adoc[completed] and still running (aka _incomplete_) Spark applications with event log collection enabled (using xref:ROOT:spark-SparkListener-EventLoggingListener.adoc#spark_eventLog_enabled[spark.eventLog.enabled] configuration property).

.History Server's web UI
image::spark-history-server-webui.png[align="center"]

Spark History Server is an extension of Spark's xref:webui:index.adoc[web UI].

Spark History Server can be started using <<start_history_server_sh, start-history-server.sh>> and stopped using <<stop_history_server_sh, stop-history-server.sh>> shell scripts.

`start-history-server.sh` accepts `--properties-file [propertiesFile]` command-line option that specifies the properties file with the custom xref:ROOT:spark-properties.adoc[Spark properties].

[source,plaintext]
----
$ ./sbin/start-history-server.sh --properties-file history.properties
----

If not specified explicitly, Spark History Server uses the default configuration file, i.e. xref:ROOT:spark-properties.adoc#spark-defaults-conf[spark-defaults.conf].

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.deploy.history` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.deploy.history=INFO
```

Refer to xref:ROOT:spark-logging.adoc[Logging].
====

== [[start_history_server_sh]] Starting History Server -- `start-history-server.sh` Shell Script

`$SPARK_HOME/sbin/start-history-server.sh` shell script (where `SPARK_HOME` is the directory of your Spark installation) is used to start a Spark History Server instance.

[source,plaintext]
----
$ ./sbin/start-history-server.sh
starting org.apache.spark.deploy.history.HistoryServer, logging to .../spark/logs/spark-jacek-org.apache.spark.deploy.history.HistoryServer-1-japila.out
----

Internally, `start-history-server.sh` script starts xref:HistoryServer.adoc[org.apache.spark.deploy.history.HistoryServer] standalone application (using `spark-daemon.sh` shell script).

[source,plaintext]
----
$ ./bin/spark-class org.apache.spark.deploy.history.HistoryServer
----

TIP: Using the more explicit approach with `spark-class` to start Spark History Server could be easier to trace execution by seeing the logs printed out to the standard output and hence terminal directly.

When started, `start-history-server.sh` prints out the following INFO message to the logs:

```
Started daemon with process name: [processName]
```

`start-history-server.sh` registers signal handlers (using `SignalUtils`) for `TERM`, `HUP`, `INT` to log their execution:

```
RECEIVED SIGNAL [signal]
```

`start-history-server.sh` inits security if enabled (using `spark.history.kerberos.enabled` setting).

CAUTION: FIXME Describe `initSecurity`

`start-history-server.sh` creates a `SecurityManager`.

`start-history-server.sh` creates a xref:ApplicationHistoryProvider.adoc[ApplicationHistoryProvider] (by reading <<spark_history_provider, spark.history.provider>>).

In the end, `start-history-server.sh` creates a xref:HistoryServer.adoc[HistoryServer] and requests it to bind to the port as configured using <<spark_history_ui_port, spark.history.ui.port>> Spark property.

[TIP]
====
The host's IP can be specified using `SPARK_LOCAL_IP` environment variable (defaults to `0.0.0.0`).
====

`start-history-server.sh` prints out the following INFO message to the logs:

```
Bound HistoryServer to [host], and started at [webUrl]
```

`start-history-server.sh` registers a shutdown hook to call `stop` on the `HistoryServer` instance.

TIP: Use <<stop_history_server, stop-history-server.sh>> shell script to to stop a running History Server.

== [[stop_history_server_sh]] Stopping History Server -- `stop-history-server.sh` Shell Script

`$SPARK_HOME/sbin/stop-history-server.sh` shell script (where `SPARK_HOME` is the directory of your Spark installation) is used to stop a running instance of Spark History Server.

[source,plaintext]
----
$ ./sbin/stop-history-server.sh
stopping org.apache.spark.deploy.history.HistoryServer
----

== [[properties]] Spark Properties

[cols="30m,30,40",options="header",width="100%"]
|===
| Setting
| Default Value
| Description

| spark.history.ui.port
| `18080`
| [[spark_history_ui_port]] The port of the History Server's UI.

| spark.history.fs.logDirectory
| `file:/tmp/spark-events`
| [[spark_history_fs_logDirectory]] The directory with the event logs. The directory has to exist before starting History Server.

| spark.history.retainedApplications
| `50`
| [[spark.history.retainedApplications]] How many Spark applications to retain.

| spark.history.ui.maxApplications
| (unbounded)
| [[spark.history.ui.maxApplications]] how many Spark applications to show in the UI.

| spark.history.kerberos.enabled
| `false`
| [[spark.history.kerberos.enabled]] Enable security when working with HDFS with security enabled (Kerberos).

| spark.history.kerberos.principal
| (empty)
| [[spark.history.kerberos.principal]] Kerberos principal. Required when `spark.history.kerberos.enabled` is enabled.

| spark.history.kerberos.keytab
| (empty)
| [[spark.history.kerberos.keytab]] Keytab to use for login to Kerberos. Required when `spark.history.kerberos.enabled` is enabled.

| spark.history.provider
| xref:FsHistoryProvider.adoc[org.apache.spark.deploy.history.FsHistoryProvider]
| [[spark_history_provider]] The fully-qualified class name for a xref:ApplicationHistoryProvider.adoc[ApplicationHistoryProvider].
|===
