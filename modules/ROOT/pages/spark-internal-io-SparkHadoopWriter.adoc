= SparkHadoopWriter

`SparkHadoopWriter` is...FIXME

== [[write]] Writing Key-Value RDD Out -- `write` Utility

[source, scala]
----
write[K, V: ClassTag](
  rdd: RDD[(K, V)],
  config: HadoopWriteConfigUtil[K, V]): Unit
----

`write`...FIXME

NOTE: `write` is used when `PairRDDFunctions` is requested to <<spark-rdd-PairRDDFunctions.adoc#saveAsNewAPIHadoopDataset, saveAsNewAPIHadoopDataset>> and <<spark-rdd-PairRDDFunctions.adoc#saveAsHadoopDataset, saveAsHadoopDataset>>.

== [[executeTask]] `executeTask` Internal Utility

[source, scala]
----
executeTask[K, V: ClassTag](
  context: TaskContext,
  config: HadoopWriteConfigUtil[K, V],
  jobTrackerId: String,
  commitJobId: Int,
  sparkPartitionId: Int,
  sparkAttemptNumber: Int,
  committer: FileCommitProtocol,
  iterator: Iterator[(K, V)]): TaskCommitMessage
----

`executeTask`...FIXME

NOTE: `executeTask` is used when `SparkHadoopWriter` utility is used to <<write, write>>.
