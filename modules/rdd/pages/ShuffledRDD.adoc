== [[ShuffledRDD]] ShuffledRDD

*ShuffledRDD* is an xref:index.adoc[RDD] of key-value pairs (`RDD[(K, C)]`) that represents a *shuffle step* in a xref:spark-rdd-lineage.adoc[RDD lineage].

ShuffledRDD is a `RDD[(K, C)]` that <<compute, computes>> key-value pairs of `K` and `C` types, respectively. When <<creating-instance, created>>, ShuffledRDD is given an <<prev, RDD>> of key-value pairs of `K` and `V` types, respectively.

ShuffledRDD is <<creating-instance, created>> for the following RDD transformations:

* xref:spark-rdd-transformations.adoc#coalesce[RDD.coalesce] (with `shuffle` flag enabled)

* xref:spark-rdd-PairRDDFunctions.adoc#combineByKeyWithClassTag[PairRDDFunctions.combineByKeyWithClassTag] and xref:spark-rdd-PairRDDFunctions.adoc#partitionBy[PairRDDFunctions.partitionBy]

* xref:spark-rdd-OrderedRDDFunctions.adoc#sortByKey[OrderedRDDFunctions.sortByKey] and xref:spark-rdd-OrderedRDDFunctions.adoc#repartitionAndSortWithinPartitions[OrderedRDDFunctions.repartitionAndSortWithinPartitions]

ShuffledRDD uses custom <<ShuffledRDDPartition, ShuffledRDDPartition>> partitions.

.Demo: ShuffledRDD and coalesce Example
```
val data = sc.parallelize(0 to 9)
val coalesced = data.coalesce(numPartitions = 4, shuffle = true)
scala> println(coalesced.toDebugString)
(4) MapPartitionsRDD[9] at coalesce at <pastie>:75 []
 |  CoalescedRDD[8] at coalesce at <pastie>:75 []
 |  ShuffledRDD[7] at coalesce at <pastie>:75 []
 +-(16) MapPartitionsRDD[6] at coalesce at <pastie>:75 []
    |   ParallelCollectionRDD[5] at parallelize at <pastie>:74 []
```

.Demo: ShuffledRDD and sortByKey Example
```
val data = sc.parallelize(0 to 9)
val grouped = rdd.groupBy(_ % 2)
val sorted = grouped.sortByKey(numPartitions = 2)
scala> println(sorted.toDebugString)
(2) ShuffledRDD[15] at sortByKey at <console>:74 []
 +-(4) ShuffledRDD[12] at groupBy at <console>:74 []
    +-(4) MapPartitionsRDD[11] at groupBy at <console>:74 []
       |  MapPartitionsRDD[9] at coalesce at <pastie>:75 []
       |  CoalescedRDD[8] at coalesce at <pastie>:75 []
       |  ShuffledRDD[7] at coalesce at <pastie>:75 []
       +-(16) MapPartitionsRDD[6] at coalesce at <pastie>:75 []
          |   ParallelCollectionRDD[5] at parallelize at <pastie>:74 []
```

[[isBarrier]]
ShuffledRDD has <<spark-rdd-RDD.adoc#isBarrier, isBarrier>> flag always disabled (`false`).

=== [[creating-instance]] Creating Instance

ShuffledRDD takes the following to be created:

* [[prev]] Previous <<spark-rdd-RDD.adoc#, RDD>> of key-value pairs (`RDD[_ <: Product2[K, V]]`)
* [[part]] <<spark-rdd-Partitioner.adoc#, Partitioner>>

=== [[compute]] Computing Partition (in TaskContext) -- `compute` Method

[source, scala]
----
compute(
  split: Partition,
  context: TaskContext): Iterator[(K, C)]
----

NOTE: `compute` is part of xref:spark-rdd-RDD.adoc#compute[RDD] contract to compute a xref:spark-rdd-Partition.adoc[partition] (in a xref:ROOT:spark-TaskContext.adoc[TaskContext]).

`compute` takes the only xref:spark-rdd-RDD.adoc#dependencies[dependency] that is assumed a xref:rdd:ShuffleDependency.adoc[ShuffleDependency] (`ShuffleDependency[K, V, C]`).

`compute` uses the xref:ROOT:spark-SparkEnv.adoc[SparkEnv] to access the xref:shuffle:ShuffleManager.adoc#shuffleManager[ShuffleManager].

`compute` requests `ShuffleManager` for a xref:shuffle:ShuffleManager.adoc#getReader[ShuffleReader] to xref:ROOT:spark-shuffle-ShuffleReader.adoc#read[read] the key-value pairs from the xref:rdd:ShuffleDependency.adoc#shuffleHandle[ShuffleHandle] for the input `split` partition.

=== [[getPreferredLocations]] Getting Placement Preferences of Partition -- `getPreferredLocations` Method

[source, scala]
----
getPreferredLocations(
  partition: Partition): Seq[String]
----

NOTE: `getPreferredLocations` is part of xref:index.adoc#getPreferredLocations[RDD] contract to specify placement preferences (aka _preferred task locations_), i.e. where tasks should be executed to be as close to the data as possible.

Internally, `getPreferredLocations` requests `MapOutputTrackerMaster` for the xref:scheduler:MapOutputTrackerMaster.adoc#getPreferredLocationsForShuffle[preferred locations], i.e. xref:ROOT:BlockManager.adoc[BlockManagers] with the most map outputs, for the input `partition` (of the one and only xref:rdd:ShuffleDependency.adoc[ShuffleDependency]).

NOTE: `getPreferredLocations` uses `SparkEnv` to access the current xref:ROOT:spark-SparkEnv.adoc#mapOutputTracker[MapOutputTrackerMaster] (which runs on the driver).

=== [[getDependencies]] Dependencies -- `getDependencies` Method

[source, scala]
----
getDependencies: Seq[Dependency[_]]
----

NOTE: `getDependencies` is part of xref:index.adoc#getDependencies[RDD] contract to describe the xref:spark-rdd-Dependency.adoc[Dependencies].

`getDependencies` uses the <<userSpecifiedSerializer, user-specified Serializer>> if defined or requests the current xref:ROOT:spark-SerializerManager.adoc[SerializerManager] for xref:ROOT:spark-SerializerManager.adoc#getSerializer[one].

`getDependencies` uses the <<mapSideCombine, mapSideCombine>> internal flag for the types of the keys and values (i.e. `K` and `C` or `K` and `V` when the flag is enabled or not, respectively).

In the end, `getDependencies` returns a single xref:rdd:ShuffleDependency.adoc[ShuffleDependency] (with the <<prev, previous RDD>>, the <<part, Partitioner>>, and the Serializer).

=== [[ShuffledRDDPartition]] ShuffledRDDPartition

`ShuffledRDDPartition` gets an `index` when it is created (that in turn is the index of partitions as calculated by the xref:spark-rdd-Partitioner.adoc[Partitioner] of a <<ShuffledRDD, ShuffledRDD>>).

=== [[internal-properties]] Internal Properties

[cols="30m,70",options="header",width="100%"]
|===
| Name
| Description

| mapSideCombine
a| [[mapSideCombine]] *Map-Side Combine* flag to select the xref:ROOT:spark-Serializer.adoc[Serializer] when ShuffledRDD is requested for the <<getDependencies, dependencies>> (i.e. a single xref:rdd:ShuffleDependency.adoc[ShuffleDependency] with the <<prev, previous RDD>>).

[source, scala]
----
mapSideCombine: Boolean = false
----

`mapSideCombine` is disabled (`false`) by default and can be changed using `setMapSideCombine` method (that is used for xref:spark-rdd-PairRDDFunctions.adoc#combineByKeyWithClassTag[PairRDDFunctions.combineByKeyWithClassTag] transformation).

| userSpecifiedSerializer
a| [[userSpecifiedSerializer]] User-specified xref:ROOT:spark-Serializer.adoc[Serializer] for the single xref:rdd:ShuffleDependency.adoc[ShuffleDependency] dependency

[source, scala]
----
userSpecifiedSerializer: Option[Serializer] = None
----

`userSpecifiedSerializer` is undefined (`None`) by default and can be changed using `setSerializer` method (that is used for xref:spark-rdd-PairRDDFunctions.adoc#combineByKeyWithClassTag[PairRDDFunctions.combineByKeyWithClassTag] transformation).

|===
