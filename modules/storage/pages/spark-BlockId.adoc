= BlockId

*BlockId* is the <<contract, abstraction>> of <<implementations, block data identifiers>> that are uniquely identified by a <<name, name>>.

[[contract]]
.BlockId Contract (Abstract Methods Only)
[%autowidth.spread,cols="20m,80",options="header"]
|===
| Method
| Description

| name
a| [[name]]

[source, scala]
----
name: String
----

Used when...FIXME

|===

NOTE: BlockId is a Scala sealed abstract class and so all the possible <<implementations, implementations>> are in the single Scala file alongside BlockId.

[[implementations]]
.BlockIds
[cols="1m,3",options="header",width="100%"]
|===
| BlockId
| Description

| BroadcastBlockId
a| [[BroadcastBlockId]] BlockId for xref:ROOT:Broadcast.adoc[]s with `broadcastId` identifier and optional `field` name (default: `empty`)

Uses `broadcast_` prefix for the <<name, name>>

Used when:

* TorrentBroadcast is xref:core:TorrentBroadcast.adoc#broadcastId[created], requested to xref:core:TorrentBroadcast.adoc#writeBlocks[store a broadcast and the blocks in a local BlockManager], and <<readBlocks, read blocks>>

* BlockManager is requested to xref:storage:BlockManager.adoc#removeBroadcast[remove all the blocks of a broadcast variable]

* AppStatusListener is requested to xref:ROOTspark-SparkListener-AppStatusListener.adoc#updateBroadcastBlock[updateBroadcastBlock] (when xref:ROOTspark-SparkListener-AppStatusListener.adoc#onBlockUpdated[onBlockUpdated] for a `BroadcastBlockId`)

xref:serializer:SerializerManager.adoc#shouldCompress[Compressed] when xref:core:BroadcastManager.adoc#spark.broadcast.compress[spark.broadcast.compress] configuration property is enabled

| RDDBlockId
a| [[RDDBlockId]] BlockId for RDD partitions with `rddId` and `splitIndex` identifiers

Uses `rdd_` prefix for the <<name, name>>

Used when:

* `StorageStatus` is requested to <<spark-blockmanager-StorageStatus.adoc#addBlock, register the status of a data block>>, <<spark-blockmanager-StorageStatus.adoc#getBlock, get the status of a data block>>, <<spark-blockmanager-StorageStatus.adoc#updateStorageInfo, updateStorageInfo>>

* `LocalCheckpointRDD` is requested to `compute` a partition

* LocalRDDCheckpointData is requested to xref:rdd:LocalRDDCheckpointData.adoc#doCheckpoint[doCheckpoint]

* `RDD` is requested to xref:rdd:RDD.adoc#getOrCompute[getOrCompute]

* `DAGScheduler` is requested for the xref:scheduler:DAGScheduler.adoc#getCacheLocs[BlockManagers (executors) for cached RDD partitions]

* `AppStatusListener` is requested to <<spark-SparkListener-AppStatusListener.adoc#updateRDDBlock, updateRDDBlock>> (when <<spark-SparkListener-AppStatusListener.adoc#onBlockUpdated, onBlockUpdated>> for a `RDDBlockId`)

xref:serializer:SerializerManager.adoc#shouldCompress[Compressed] when xref:ROOT:configuration-properties.adoc#spark.rdd.compress[spark.rdd.compress] configuration property is enabled (default: `false`)

| ShuffleBlockId
a| [[ShuffleBlockId]] BlockId for _FIXME_ with `shuffleId`, `mapId`, and `reduceId` identifiers

Uses `shuffle_` prefix for the <<name, name>>

Used when:

* `ShuffleBlockFetcherIterator` is requested to xref:storage:ShuffleBlockFetcherIterator.adoc#throwFetchFailedException[throwFetchFailedException]

* `MapOutputTracker` object is requested to xref:scheduler:MapOutputTracker.adoc#convertMapStatuses[convertMapStatuses]

* `SortShuffleWriter` is requested to xref:shuffle:SortShuffleWriter.adoc#write[write partition records]

* `ShuffleBlockResolver` is requested for a xref:shuffle:ShuffleBlockResolver.adoc#getBlockData[ManagedBuffer to read shuffle block data file]

xref:serializer:SerializerManager.adoc#shouldCompress[Compressed] when xref:ROOT:configuration-properties.adoc#spark.shuffle.compress[spark.shuffle.compress] configuration property is enabled (default: `true`)

| ShuffleDataBlockId
| [[ShuffleDataBlockId]]

| ShuffleIndexBlockId
| [[ShuffleIndexBlockId]]

| StreamBlockId
| [[StreamBlockId]]

| TaskResultBlockId
| [[TaskResultBlockId]]

| TempLocalBlockId
| [[TempLocalBlockId]]

| TempShuffleBlockId
| [[TempShuffleBlockId]]

|===

== [[apply]] Creating BlockId -- `apply` Factory Method

[source, scala]
----
apply(name: String): BlockId
----

`apply` simply creates a concrete <<implementations, BlockId>> by the given name.

NOTE: `apply` is used when...FIXME
