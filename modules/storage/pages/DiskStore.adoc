= DiskStore

*DiskStore* is...FIXME

DiskStore is <<creating-instance, created>> for xref:storage:BlockManager.adoc#diskStore[BlockManager].

== [[creating-instance]] Creating Instance

`DiskStore` takes the following to be created:

* [[conf]] xref:ROOT:spark-SparkConf.adoc[SparkConf]
* [[diskManager]] xref:storage:DiskBlockManager.adoc[DiskBlockManager]
* [[securityManager]] SecurityManager

== [[contains]] Checking if Block File Exists

[source, scala]
----
contains(
  blockId: BlockId): Boolean
----

`contains` requests the <<diskManager, DiskBlockManager>> for the xref:storage:DiskBlockManager.adoc#getFile[block file] by (the name of) the input xref:storage:spark-BlockId.adoc[BlockId] and check whether the file actually exists or not.

`contains` is used when:

* BlockManager is requested to xref:storage:BlockManager.adoc#getStatus[getStatus], xref:storage:BlockManager.adoc#getCurrentBlockStatus[getCurrentBlockStatus], xref:storage:BlockManager.adoc#getLocalValues[getLocalValues], xref:storage:BlockManager.adoc#doGetLocalBytes[doGetLocalBytes], xref:storage:BlockManager.adoc#dropFromMemory[dropFromMemory]

* DiskStore is requested to <<put, put>>

== [[put]] Writing Block

[source, scala]
----
put(
  blockId: BlockId)(
  writeFunc: WritableByteChannel => Unit): Unit
----

`put`...FIXME

`put` is used when:

* BlockManager is requested to xref:storage:BlockManager.adoc#doPutIterator[doPutIterator] and xref:storage:BlockManager.adoc#dropFromMemory[dropFromMemory]

* DiskStore is requested to <<putBytes, putBytes>>

== [[putBytes]] putBytes Method

[source, scala]
----
putBytes(
  blockId: BlockId,
  bytes: ChunkedByteBuffer): Unit
----

`putBytes`...FIXME

`putBytes` is used when BlockManager is requested to xref:storage:BlockManager.adoc#doPutBytes[doPutBytes] and xref:storage:BlockManager.adoc#dropFromMemory[dropFromMemory].

== [[remove]] Removing Block

[source, scala]
----
remove(
  blockId: BlockId): Boolean
----

`remove`...FIXME

`remove` is used when:

* BlockManager is requested to xref:storage:BlockManager.adoc#removeBlockInternal[removeBlockInternal]

* DiskStore is requested to <<put, put>> (when an exception was thrown)

== [[logging]] Logging

Enable `ALL` logging level for `org.apache.spark.storage.DiskStore` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

[source]
----
log4j.logger.org.apache.spark.storage.DiskStore=ALL
----

Refer to xref:ROOT:spark-logging.adoc[Logging].
